# Senet

Category: Convolutional

Summary

Squeeze-and-Excitation channel attention blocks.

Key Ideas

- Architecture motivation
- Core building blocks
- Training considerations
- Typical applications

Detailed Flow

```
[Feature maps] -> [Squeeze (global pooling) -> Excitation (MLP)] -> [Scale channels] -> [Next blocks]
```

Canonical Papers

Further Reading

- Search for more resources on Senet.

