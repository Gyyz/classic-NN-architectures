# Distilbert

Category: Transformer

Summary

Smaller BERT via knowledge distillation.

Key Ideas

- Architecture motivation
- Core building blocks
- Training considerations
- Typical applications

Minimal Diagram

```
[Input] -> [Layers/Blocks] -> [Output]
```

Canonical Papers

Further Reading

- Search for more resources on Distilbert.

Generated on 2025-11-24.