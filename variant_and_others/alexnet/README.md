# Alexnet

Category: Convolutional

Summary

Deep CNN that popularized ReLU, dropout, and GPU training.

Key Ideas

- Architecture motivation
- Core building blocks
- Training considerations
- Typical applications

Detailed Flow

```
[Image] -> [Conv -> ReLU -> LRN -> MaxPool] Ã— stacks -> [FC -> ReLU]*2 -> [FC -> Softmax]
```

Canonical Papers

Further Reading

- Search for more resources on Alexnet.

