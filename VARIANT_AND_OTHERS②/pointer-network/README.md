# Pointer Network

Category: Transformer

Summary

Attention-based model for outputs that are pointers to inputs.

Key Ideas

- Architecture motivation
- Core building blocks
- Training considerations
- Typical applications

Detailed Flow

```
[Sequence] -> [Encoder] -> [Decoder with attention over inputs] -> [Pointer indices as outputs]
```

Canonical Papers

Further Reading

- Search for more resources on Pointer Network.

